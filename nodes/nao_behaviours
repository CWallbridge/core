#!/usr/bin/env python
"""
Listens for a trajectory to write and sends it to the nao via naoqi SDK.

Requires a running robot/simulation with ALNetwork proxies.

"""
from copy import deepcopy
from naoqi import ALModule, ALBroker, ALProxy
from geometry_msgs.msg import PoseStamped
from nav_msgs.msg import Path
from std_msgs.msg import String
from std_msgs.msg import Empty
from time import sleep
import rospy
import tf
import motion
import numpy
import math
import random
import time
import sys
import os

import underworlds
import underworlds.server
from underworlds.tools.loader import ModelLoader
from underworlds.tools.spatial_relations import *
from underworlds.tools.edit import *

import csv
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix

from placement_description import *

TO_RAD = math.pi / 180

# masks for which axes naoqi is to control with its planning
axisMask=motion.AXIS_MASK_VEL
#axisMask=motion.AXIS_MASK_ALL

HEAD_FRAME="Head"

NAO_ARM_LENGTH=0.105 #m -> lenght of the link RBicep, from URDF
NAO_FOREARM_LENGTH=0.11 #m -> approx. lenght of forearm + half hand

# See
# http://doc.aldebaran.com/1-14/family/robots/joints_robot.html#robot-joints-v4-left-arm-joints
NAO_RSHOULDER_ANGLE_LIMITS = [-76 * TO_RAD, 18 * TO_RAD]
NAO_RELBOW_ANGLE_LIMITS = [2 * TO_RAD, 88.5 * TO_RAD]

tl = None

is_tracking_focus = False
robot_ready_to_point = False

last_pose = None
state = "idle"

#cur_map = 0
ctx = underworlds.Context("Nao Description")

target = numpy.empty((2,7), dtype="a36")
na_desc = [[]]
obj_frame_id = [[]]

order = 0
cond1 = "N"
cond2 = "D"
cur_targ = 0
cur_map = 0
new_desc = True
cur_targ_frame = "1_1_target"
cur_obj_id = ""
d_rel_list = []
iteration = 0
full_desc = ""

target_change = False

def clamp(v, limits):
    vmin, vmax = limits
    return max(min(v, vmax), vmin)


def xyz2pantilt(pose, headframe=HEAD_FRAME):
    """
    Convert a xyz target to pan and tilt angles for the head.

    :param headframe: the frame of the head
    :returns: (pan, tilt) in radians
    """
    #tl.waitForTransform(headframe,pose.header.frame_id, rospy.Time.now(), rospy.Duration(1.0))
    pose.header.stamp = tl.getLatestCommonTime(pose.header.frame_id, headframe)
    transformed_pose = tl.transformPose(headframe, pose)
    pan = numpy.arctan2(transformed_pose.pose.position.y, transformed_pose.pose.position.x)
    tilt = numpy.arctan2(transformed_pose.pose.position.z, transformed_pose.pose.position.x)

    return (pan,tilt)

def look_at(targetpose):

    reference_frame = "torso"
    try:
        targetpose.header.stamp = tl.getLatestCommonTime(targetpose.header.frame_id,reference_frame)
        pose = tl.transformPose(reference_frame, targetpose)
        target = [pose.pose.position.x,pose.pose.position.y,pose.pose.position.z]
    except:
        print "error poses"
        return
        
    trackerProxy.post.lookAt(target, 0, .3, False)

    return


def arm_ik(targetpose, reference_frame="RShoulder"):
    """
    Returns (shoulder_joint, elbow_joint) such as the arm points towards the
    target (x,y). We make a simple 2D approximation.

              Y
     X target ^
      \  (x,y)|    O
       \      |     \l2
        \     |      \  elbow_joint
         \    |       O
          \   |      /
          `.  |     /l1
           |  |   ,'
            \ |  /
             \| / shoulder_joint
              O:............> X
    """

    targetpose.header.stamp = tl.getLatestCommonTime(targetpose.header.frame_id,reference_frame)
    pose = tl.transformPose(reference_frame, targetpose)

    # rotate the shoulder frame: on the robot, X points forward, on the drawing above, X points right
    x = -pose.pose.position.y
    y = pose.pose.position.x


    l1=NAO_ARM_LENGTH
    l2=NAO_FOREARM_LENGTH

    if x == 0 and y == 0:
        return None
    if y < 0: # do not allow gestures *behind* the robot
        return None

    if (math.sqrt(x*x + y*y) > l1+l2):
        shoulder_angle = -math.pi/2 + math.atan2(y,x)
        elbow_angle = 0.0
        if shoulder_angle > NAO_RSHOULDER_ANGLE_LIMITS[1]:
            elbow_angle = shoulder_angle

    else:
        # planar solution of the Inverse Kinematic problem
        elbow_angle = math.acos((x*x + y*y - l1*l1 - l2*l2)/(2*l1*l2))

        # note: -pi/2 comes from the orientation of Nao's joint (-> angle = 0 <=> arm pointing forward)
        shoulder_angle = -math.pi/2 + math.asin(y/math.sqrt(x*x + y*y)) - math.asin(l2 *
                                                math.sin(elbow_angle)/math.sqrt(x*x + y*y))


    return clamp(shoulder_angle, NAO_RSHOULDER_ANGLE_LIMITS),clamp(elbow_angle,NAO_RELBOW_ANGLE_LIMITS)



def point_at(targetpose):
    angles = arm_ik(targetpose)

    if angles is None:
        return

    names  = ["RShoulderRoll",
              "RElbowRoll"]
    rospy.logdebug("Moving shoulder, elbow: %s" % str([angles[0]/TO_RAD, angles[1]/TO_RAD]))
    fractionMaxSpeed  = 0.3
    motionProxy.setAngles(names, angles, fractionMaxSpeed)

def set_pointing_posture():
    global robot_ready_to_point

    if not robot_ready_to_point:
        names  = ["RShoulderRoll",
                "RShoulderPitch",
                "RElbowRoll",
                "RElbowYaw",
                "RWristYaw"]
        angleLists  = [[-10 * TO_RAD, -75 * TO_RAD, -75 * TO_RAD, -35 * TO_RAD],
                    [70 * TO_RAD, 70 * TO_RAD, 10 * TO_RAD],
                    [2 * TO_RAD, 2 * TO_RAD, 60 * TO_RAD],
                    [0 * TO_RAD],
                    [0 * TO_RAD]]
        timeLists   = [[1.0, 3.0,4.0,5.0],
                    [1.0, 3.0, 4.0],
                    [1.0,4.0,5.0],
                    [1.0],
                    [1.0]]
        isAbsolute  = True
        motionProxy.angleInterpolation(names, angleLists, timeLists, isAbsolute) #blocking!

    robot_ready_to_point = True

def arm_to_rest_posture():
    global robot_ready_to_point

    if robot_ready_to_point:
        names  = ["RShoulderRoll",
                "RShoulderPitch",
                "RElbowRoll"]
        angleLists  = [[-75 * TO_RAD, -75 * TO_RAD, -10 * TO_RAD],
                    [10 * TO_RAD, 70 * TO_RAD],
                    [2 * TO_RAD]]
        timeLists   = [[1.0, 3.0, 5.0],
                    [1.0, 3.0],
                    [1.5]]
        isAbsolute  = True
        motionProxy.angleInterpolation(names, angleLists, timeLists, isAbsolute) #blocking!

    robot_ready_to_point = False

def arm_between_pointing_posture():
    names  = ["RShoulderRoll",
              "RElbowRoll"]
    angleLists  = [[-random.randint(30,40) * TO_RAD],
                   [random.randint(50,70) * TO_RAD]]
    timeLists   = [[1.0],
               [1.0]]
    isAbsolute  = True
    motionProxy.angleInterpolation(names, angleLists, timeLists, isAbsolute) #blocking!

def on_pose(pose):
    global last_pose

    if is_tracking_focus:
        rospy.logwarn("Received a path, but Nao is going to ignore it as it currently track the ' robot focus'")
        return

    if(hasFallen == False): #no harm in executing trajectory
        #if(effector == "LArm"):
        #    motionProxy.openHand("LHand");
        #    roll = -1.7; #rotate wrist to the left (about the x axis, w.r.t. robot frame)
        #else:
        #    motionProxy.openHand("RHand");
        #    roll = 1.7; #rotate wrist to the right (about the x axis, w.r.t. robot frame)

        if not robot_ready_to_point:
            set_pointing_posture()
        else:
            point_at(pose)
            look_at(pose)

        last_pose = rospy.Time.now()


    else:
        rospy.loginfo("Got pose to look at, but I've fallen!");

class FallResponder(ALModule):
  """ Module to react to robotHasFallen events """

  def __init__(self, name, motionProxy, memoryProxy):
      ALModule.__init__(self, name)
      self.motionProxy = motionProxy;
      memoryProxy.subscribeToEvent("robotHasFallen",name,self.has_fallen.__name__);
      rospy.loginfo("Subscribed to robotHasFallen event");
  def has_fallen(self, *_args):
      global hasFallen
      hasFallen = True;
      self.motionProxy.killAll();
      rospy.loginfo("Stopped task");

def build_classifier():
    
    train = []
    trainresult = []
    test = []
    testresult = []
    
    with open('res/train.csv', 'rb') as csvfile:
    
        trainreader = csv.reader(csvfile, delimiter = ',', quotechar ='|')
        
        for row in trainreader:
            
            if train == []:
                train = numpy.append(train, [row[0], row[1], row[2], row[3]])
            else:
                train = numpy.vstack((train, [row[0], row[1], row[2], row[3]]))
            
            trainresult = numpy.append(trainresult, [row[4]])

        clf = SVC(gamma='auto', kernel='rbf')
        clf.fit(train, trainresult) 
    
    with open('res/test.csv', 'rb') as csvtestfile:
        
        testreader = csv.reader(csvtestfile, delimiter = ',', quotechar ='|')
        
        for row in testreader:
            
            if test == []:
                test = numpy.append(test, [row[0], row[1], row[2], row[3]])
            else:
                test = numpy.vstack((test, [row[0], row[1], row[2], row[3]]))
            
            testresult = numpy.append(testresult, [row[4]])

        print(clf.score(test, testresult))
        predresult = clf.predict(test)
        
        print confusion_matrix(testresult, predresult)
        
    return clf

def set_condition(message):
    global order
    global cond1
    global cond2
    
    conditions = message.data
    
    order, cond1, cond2 = conditions.split('-')

def na_description(cur_map, targ):
    
    global new_desc
    new_desc = False
    
    msg = na_desc[cur_map][targ]
    
    targetpose = PoseStamped()        
    targetpose.header.frame_id = str(cur_map + 1) + "_" + str(targ + 1) + "_target"
    targetpose.header.stamp = rospy.Time(0)
    
    look_at(targetpose)
    
    pub_rob_start.publish()
    say_id = textSpchProxy.post.say(msg)
    textSpchProxy.wait(say_id, 0)
    
    trackerProxy.lookAt([1,0,0.6], 0, .1,False)
    
    pub_rob_end.publish()
    
    return rospy.Time.now()
   
def d_description(node_id, decision):

    global new_desc
    global d_rel_list
    global cur_map
    global ctx
    global iteration
    global full_desc
    global cur_targ
    global state
    
    #state = "wait"
    
    if cur_map == 0:
        worldName = "map1"
    else:
        worldName = "map2"
    
    if new_desc == True:
        
        new_desc = False
        desc, d_rel_list = dynamic_desc(ctx, worldName, [], node_id, 0, "initial", "default", "en_GB", True)
        full_desc = desc
        iteration = 1
        
    elif decision == "elaborate":
        if iteration < 4:
            desc, d_rel_list = dynamic_desc(ctx, worldName, d_rel_list, node_id, iteration, decision, "default", "en_GB", True)
            iteration = iteration + 1
            full_desc = full_desc + ', ' + desc
        else:
            desc = full_desc
            
    else:
        desc, d_rel_list = dynamic_desc(ctx, worldName, d_rel_list, node_id, iteration, decision, "default", "en_GB", True)
    
    print desc
    
    targetpose = PoseStamped()        
    targetpose.header.frame_id = str(cur_map + 1) + "_" + str(cur_targ + 1) + "_target"
    targetpose.header.stamp = rospy.Time(0)
    
    look_at(targetpose)
    
    pub_rob_start.publish()
    say_id = textSpchProxy.post.say(str(desc))
    textSpchProxy.wait(say_id, 0)
    
    trackerProxy.lookAt([1,0,0.6], 0, .1,False)
    
    pub_rob_end.publish()
    
    #state = "d_describe"
    
    return rospy.Time.now()
    
def command(message):
    
    global order
    global cond1
    global cond2
    global cur_targ
    global state
    global cur_map
    global new_desc
    global cur_targ_frame
    
    if message.data == "tutorial":
        
        trackerProxy.lookAt([1,0,0.6], 0, .1,False)
        trackerProxy.registerTarget("Face",.2)
        trackerProxy.track("Face")
    
        msg = "Hello. "
        msg = msg + "I am Pico, today we are going to play a game together. \pau=500\ "
        msg = msg + "In a moment we are going to see the map of a city. \pau=500\ "
        msg = msg + "However some of the buildings from the city are missing. \pau=500\ "
        msg = msg + "You will see some buildings pop up with a red border, you can move them around by touching the screen. \pau=500\ "
        msg = msg + "I will be describing where these buildings should go. \pau=500\ "
        msg = msg + "In front of you right now you can see the names I will be using to describe the buildings that need to be moved, and that are already in position. \pau=500\ "
        msg = msg + "A church, a commercial district, a factory, a fire department, a hospital, a manor, a police department, a power plant, and a residence. \pau=500\ "
        msg = msg + "Let's get started!"

        msg = "\RSPD=90\ \VCT=100\ " + msg

        say_id = textSpchProxy.post.say(msg)
        textSpchProxy.wait(say_id, 0)
        
        pub_start_placement1.publish()
        
    elif message.data == "placement1":
        
        cur_map = int(order)
        cur_targ_frame = str(cur_map + 1) + "_" + str(cur_targ + 1) + "_target"
        new_desc = True
    
        if cond1 == "D":
            state = "d_describe"
        else:
            state = "na_describe"
    
    elif message.data == "placement2":
        
        cur_map = 1 - int(order)
        cur_targ_frame = str(cur_map + 1) + "_" + str(cur_targ + 1) + "_target"
        new_desc = True
            
        if cond2 == "D":
            state = "d_describe"
        else:
            state = "na_describe"
            
    elif message.data == "success":
        
        prev_state = state
        state = "success"
        say_id = textSpchProxy.post.say("Well done!")
        textSpchProxy.wait(say_id, 0)
        cur_targ = cur_targ + 1
        cur_targ_frame = str(cur_map + 1) + "_" + str(cur_targ + 1) + "_target"
        
        if cur_targ < 7:
            state = prev_state
            new_desc = True
        else:
            state = "idle"
            cur_targ = 0
        
        #print cur_targ_frame
        
    else:
        textSpchProxy.post.say("I am afraid I can't do that Dave")
        
    #postureProxy.goToPosture("Crouch", 0.5)
    #set_pointing_posture()

if __name__ == "__main__":
    global state
    global ctx
    global target
    global na_desc
    global cur_targ
    global cur_map
    global new_desc
    global cur_targ_frame
    global cur_obj_id
    
    na_desc = [[]]
    new_desc = True
    
    prev_x = 0
    prev_y = 0
    prev_z = 0
    previous_vector = numpy.array([0,0,0])
    
    rospy.init_node("nao_behaviours");

    last_desc = rospy.Time.now()

    POSES_TOPIC = rospy.get_param('~poses_output_topic','poses')
    NAO_IP = rospy.get_param('~nao_ip','192.168.1.112'); 
    NAO_HANDEDNESS = rospy.get_param('~nao_handedness','right')
    if(NAO_HANDEDNESS.lower()=='right'):
        effector   = "RArm"
    elif(NAO_HANDEDNESS.lower()=='left'):
        effector = "LArm"
    else:
        rospy.logerr('error in handedness param')

    pub_speech = rospy.Publisher("/speech", String, queue_size=5)
    sub_placement_start = rospy.Subscriber("nao/place_desc/command", String, command, queue_size=1)
    sub_placement_condition = rospy.Subscriber("nao/place_desc/condition", String, set_condition, queue_size=1)
    pub_start_placement1 = rospy.Publisher("/sandtray/signals/start_placement1", Empty, queue_size=1)
    pub_rob_start = rospy.Publisher("/sandtray/signals/rob_speech_start", Empty, queue_size=1)
    pub_rob_end = rospy.Publisher("/sandtray/signals/rob_speech_end", Empty, queue_size=1)

    # We need this broker to be able to construct
    # NAOqi modules and subscribe to other modules
    # The broker must stay alive until the program exists
    port = 9559;
    myBroker = ALBroker("myBroker", #I'm not sure that pyrobots doesn't already have one of these open called NAOqi?
        "0.0.0.0",   # listen to anyone
        0,           # find a free port and use it
        NAO_IP,      # parent broker IP
        port)        # parent broker port
    hasFallen = False;
    motionProxy = ALProxy("ALMotion", NAO_IP, port);
    memoryProxy = ALProxy("ALMemory", NAO_IP, port);
    postureProxy = ALProxy("ALRobotPosture", NAO_IP, port);
    trackerProxy = ALProxy("ALTracker", NAO_IP, port);
    AnmtdSpchProxy = ALProxy("ALAnimatedSpeech", NAO_IP, port);
    textSpchProxy = ALProxy("ALTextToSpeech", NAO_IP, port)
    #fallResponder = FallResponder("fallResponder",motionProxy,memoryProxy);

    state = "waiting"
    
    clf = build_classifier()
    
    if trackerProxy.isActive():
        trackerProxy.stopTracker()

    world1 = ctx.worlds["map1"]
    world2 = ctx.worlds["map2"]
    
    ModelLoader().load("res/map_wEmpty.blend", world="map1")
    ModelLoader().load("res/map2_wEmpty.blend", world="map2")
    
    time.sleep(5) # leave some time for the loader to finish
    
    target[0][0] = world1.scene.nodebyname("residence-18")[0].id
    target[0][1] = world1.scene.nodebyname("manor")[0].id
    target[0][2] = world1.scene.nodebyname("residence-7")[0].id
    target[0][3] = world1.scene.nodebyname("commercial_district-1")[0].id
    target[0][4] = world1.scene.nodebyname("police_department")[0].id
    target[0][5] = world1.scene.nodebyname("police_department-1")[0].id
    target[0][6] = world1.scene.nodebyname("church-2")[0].id
    target[1][0] = world2.scene.nodebyname("hospital-1")[0].id
    target[1][1] = world2.scene.nodebyname("hospital-2")[0].id
    target[1][2] = world2.scene.nodebyname("residence-6")[0].id
    target[1][3] = world2.scene.nodebyname("hospital")[0].id
    target[1][4] = world2.scene.nodebyname("residence-17")[0].id
    target[1][5] = world2.scene.nodebyname("manor-1")[0].id
    target[1][6] = world2.scene.nodebyname("power_plant")[0].id
    
    obj_frame_id[0].append("1_1_residential")
    obj_frame_id[0].append("1_2_manor")
    obj_frame_id[0].append("1_3_residential")
    obj_frame_id[0].append("1_4_commercial")
    obj_frame_id[0].append("1_5_police")
    obj_frame_id[0].append("1_6_police")
    obj_frame_id[0].append("1_7_church")
    obj_frame_id.append([])
    obj_frame_id[1].append("2_1_hospital")
    obj_frame_id[1].append("2_2_hospital")
    obj_frame_id[1].append("2_3_residential")
    obj_frame_id[1].append("2_4_hospital")
    obj_frame_id[1].append("2_5_residential")
    obj_frame_id[1].append("2_6_manor")
    obj_frame_id[1].append("2_7_power")
    
    for node in world1.scene.nodes:
        format_name("map1", node.id)
    
    for node in world2.scene.nodes:
        format_name("map2", node.id)
        
    time.sleep(10)
    
    i = 0
    j = 0
    
    while i < 2:
        if i == 0:
            worldname = "map1"
        else:
            worldname = "map2"
            na_desc.append([])
           
        world = ctx.worlds[worldname]
        
        target_chk = target[i]
        
        node_chk = []
        
        for node_id in target_chk:
            node_chk.append(world.scene.nodes[node_id])
        
        while j < 7:
            node_chk.pop(0)
            desc = gen_spatial_desc(ctx, worldname, target[i][j], "default", node_chk,"en_GB","NonAmbig", "placement", True)
            na_desc[i].append(str(desc))
            j = j+1
            
        j = 0
        i = i + 1

    motionProxy.wbEnableEffectorControl(effector,False); #if robot has fallen it will have a hard time getting up if the effector is still trying to be kept in a particular position
    motionProxy.wakeUp()
    post_id = postureProxy.post.goToPosture("Crouch", 0.5)
    postureProxy.wait(post_id,0)
    names = ['RKneePitch', 'LKneePitch', 'RAnklePitch', 'LAnklePitch', 'RAnkleRoll', 'LAnkleRoll']
    motionProxy.setStiffnesses(names, 0.0)
    motionProxy.setBreathEnabled("Arms", True)

    tl = tf.TransformListener()

    ### Check the robot is launched and properly localised wrt the sandtray
    while not rospy.is_shutdown() and state != "placement":

        try:
            t = tl.getLatestCommonTime("odom", "sandtray")
            if tl.canTransform("odom", "sandtray",t):
                rospy.loginfo("Ok! Starting robot behaviours.")
                #textSpchProxy.say(String("Ready to go!"))
                break
            else:
                pass
                #rospy.logwarn("No transform robot->sandtray. Robot not yet localised!")
        except:
            pass
            #rospy.logwarn("No transform robot->sandtray. Robot not yet localised!")

        rospy.sleep(0.5)

    sub_poses = rospy.Subscriber(POSES_TOPIC, PoseStamped, on_pose, queue_size=1) # queue_size = 1 to discard all but the most recent pose -- otherwise, tracking would possibly lag

    r = rospy.Rate(10)
    
    decision_list = []
    
    targ_found = False
    new_desc = False

    while not rospy.is_shutdown():
        
        try:
            t = tl.getLatestCommonTime(HEAD_FRAME, "robot_focus")
            if tl.canTransform(HEAD_FRAME, "robot_focus",t):
                is_tracking_focus = True
                robot_focus = PoseStamped()
                robot_focus.header.stamp = rospy.Time.now()
                robot_focus.header.frame_id = "robot_focus"
            else:
                is_tracking_focus = False
        except Exception as e: # most likely, robot_focus is not published. That's ok, don't track it then
            is_tracking_focus = False
            pass

                
        if state == "na_describe" and (((rospy.Time.now() - last_desc).to_sec() > 5) or (new_desc == True)):
            last_desc = na_description(cur_map, cur_targ)
        
        
        if state == "d_describe":
            
            if new_desc == True:
            
                targ_found = False
                
                prev_x = 0
                prev_y = 0
                prev_z = 0
                previous_vector = numpy.array([0,0,0])
                
                cur_obj_id = target[cur_map][cur_targ]
                
                try:
                    (trans, rot) = tl.lookupTransform(cur_targ_frame, '/sandtray', rospy.Time(0))
                    #Convert for classifier
                    target_x = trans[0] * 15
                    target_y = trans[1] * 15
                    target_z = trans[2] * 15
                    
                    targ_found = True
                    
                except Exception as e:
                    print "exception in targ_frame"
                    print e
                    pass
            
            try:

                (trans, rot) = tl.lookupTransform(obj_frame_id[cur_map][cur_targ], '/sandtray', rospy.Time(0))
                #Convert for classifier
                cur_x = trans[0] * 15
                cur_y = trans[1] * 15
                cur_z = trans[2] * 15
                
                x_vec = cur_x - prev_x
                y_vec = cur_y - prev_y
                z_vec = cur_z - prev_z
                
                vector = numpy.array([x_vec,y_vec,z_vec])
                mag = numpy.linalg.norm(vector)
                
                x_dist = target_x - cur_x
                y_dist = target_y - cur_y
                z_dist = target_z - cur_z
                
                x_prev_dist = target_x - prev_x
                y_prev_dist = target_y - prev_y
                z_prev_dist = target_z - prev_z
                
                dist_vec = numpy.array([x_dist,y_dist,z_dist])
                distance_to_target = numpy.linalg.norm(dist_vec)
                
                prev_dist_vec = numpy.array([x_prev_dist,y_prev_dist,z_prev_dist])
                prev_distance_to_target = numpy.linalg.norm(prev_dist_vec)
                
                change_in_dist = distance_to_target - prev_distance_to_target
                
                prev_mag = numpy.linalg.norm(previous_vector)
                
                if mag == 0 or prev_mag == 0:
                    angle_from_prev = 0
                else:
                    unit_vector_1 = vector/mag
                    unit_vector_2 = previous_vector/prev_mag
                    angle_from_prev = numpy.arccos(numpy.clip(numpy.dot(unit_vector_1, unit_vector_2), -1.0, 1.0))
                
                prev_x = cur_x
                prev_y = cur_y
                prev_z = cur_z
                
                previous_vector = vector
                
                pred_data = numpy.array([distance_to_target, change_in_dist, mag, angle_from_prev])
                
                shaped_data = pred_data.reshape(1,-1)
                
                decision = clf.predict(shaped_data)
                
                decision_list.append(int(decision[0]))
                
                if len(decision_list) > 5:
                    decision_list.pop(0)
                
                #print decision
            
            except Exception as e:
                print "exception in obj_frame"
                print e
                pass
                
            time_since_last = (rospy.Time.now() - last_desc).to_sec()
            
            if time_since_last > 0.5 or new_desc == True:
                if new_desc == True:
                    final_dec = "initial"
                elif len(decision_list) == 0:
                    final_dec = "elaborate"
                else:
                    print decision_list
                    avg_decision = float(sum(decision_list))/float(len(decision_list))
                    print avg_decision
                    if avg_decision < 0.8:
                        final_dec = "negate"
                    elif avg_decision > 1.5:
                        final_dec = "positive"
                    else:
                        final_dec = "elaborate"
                        
                if (final_dec == "initial") or (final_dec  == "negate") or (final_dec == "elaborate" and time_since_last >= 1) or (final_dec == "positive" and time_since_last >= 2):
                    last_desc = d_description(cur_obj_id, final_dec)
                else:
                    trackerProxy.registerTarget("Face",.2)
                    trackerProxy.track("Face")
        
        #elif cur_targ == 1:
            #targetpose = PoseStamped()        
            #targetpose.header.frame_id = "1_2_manor"
            #targetpose.header.stamp = rospy.Time(0)
            #look_at(targetpose)
            
        elif state == "wait":
            pass
        else:
            #trackerProxy.lookAt([1,0,0.6], 0, .1,False)
            trackerProxy.registerTarget("Face",.2)
            trackerProxy.track("Face")

        r.sleep()


    arm_to_rest_posture()
    motionProxy.rest()
    
    if trackerProxy.isActive():
        trackerProxy.stopTracker()

    myBroker.shutdown()
